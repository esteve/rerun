{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b31c0a84",
   "metadata": {},
   "source": [
    "## Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1076c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "from collections import namedtuple\n",
    "from math import cos, sin\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import PIL.Image\n",
    "import rerun as rr  # pip install rerun-sdk\n",
    "import rerun.blueprint as rrb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf894a1f",
   "metadata": {},
   "source": [
    "## Define neural field class\n",
    "\n",
    "First, we define the neural field class which we can be used to represent any continuous ND signal. I.e., it maps an ND point to another ND point. In this notebook we fit fields to map from 2D image coordinates to RGB colors. This way the network weights can be interpreted as encoding a continuous image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f709925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralField(torch.nn.Module):\n",
    "    \"\"\"Simple neural field composed of positional encoding, MLP, and activation function.\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_layers: int, \n",
    "        dim_hidden: int, \n",
    "        dim_in: int=2, \n",
    "        dim_out: int=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_out = dim_out\n",
    "        \n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.num_layers}-layer MLP ({self.dim_hidden} neurons)\"\n",
    "\n",
    "\n",
    "    def forward(self, input_points: torch.Tensor):\n",
    "        \"\"\"Compute output for given input points.\n",
    "\n",
    "        Args:\n",
    "            input_points: \n",
    "        \"\"\"\n",
    "        num_points = len(input_points)\n",
    "        return torch.rand(num_points, 3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c095ef",
   "metadata": {},
   "source": [
    "## Initialize and visualize neural fields\n",
    "\n",
    "Now we create a few neural fields with different parameters and visualize their output as images. We assume that images are fit in a 0 to 1 unit square, so we query in a dense grid (with some additional margin to observe out-of-training behavior) to retrieve the image from the network. Note that the positional encoding encodes how quickly the neural field varies out-of-the-box. This corresponds to the amount of detail that the field can easily represent, but also determines how the field extrapolates outside of the training region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "332d8d35-42f7-415a-b58b-9c55430cb67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-27T15:36:20Z DEBUG re_chunk::batcher] creating new chunk batcher config=ChunkBatcherConfig { flush_tick: 8ms, flush_num_bytes: 1048576, flush_num_rows: 18446744073709551615, max_chunk_rows_if_unsorted: 256, max_commands_in_flight: None, max_chunks_in_flight: None, hooks: BatcherHooks { on_insert: None, on_release: Some(ArrowChunkReleaseCallback(\"0x23e98020310\")) } }\n",
      "[2024-06-27T15:36:20Z DEBUG re_sdk::recording_stream] setting recording info app_id=rerun_example_cube rec_id=ac0064a7-1de4-423d-8284-9dd6e792faea\n",
      "[2024-06-27T15:36:20Z DEBUG re_chunk::batcher] creating new chunk batcher config=ChunkBatcherConfig { flush_tick: 8ms, flush_num_bytes: 1048576, flush_num_rows: 18446744073709551615, max_chunk_rows_if_unsorted: 256, max_commands_in_flight: None, max_chunks_in_flight: None, hooks: BatcherHooks { on_insert: None, on_release: Some(ArrowChunkReleaseCallback(\"0x23e98020a50\")) } }\n",
      "[2024-06-27T15:36:20Z DEBUG re_sdk::recording_stream] setting recording info app_id=rerun_example_cube rec_id=04b2e329-875a-4c15-a6ca-fe996be72235\n",
      "[2024-06-27T15:36:20Z DEBUG re_sdk::recording_stream] setting recording info app_id=rerun_example_cube rec_id=04b2e329-875a-4c15-a6ca-fe996be72235\n",
      "[2024-06-27T15:36:21Z DEBUG re_sdk::recording_stream] setting recording info app_id=rerun_example_cube rec_id=ac0064a7-1de4-423d-8284-9dd6e792faea\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9898a610676b4a678547c6093cbd913d",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Viewer()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fields = [\n",
    "    NeuralField(num_layers=4, dim_hidden=32),\n",
    "    NeuralField(num_layers=4, dim_hidden=64),\n",
    "    NeuralField(num_layers=4, dim_hidden=128),\n",
    "    NeuralField(num_layers=4, dim_hidden=256)\n",
    "]\n",
    "total_iterations = [0 for _ in fields]\n",
    "\n",
    "rr.init(\"rerun_example_cube\")\n",
    "\n",
    "blueprint = rrb.Blueprint(\n",
    "    rrb.Vertical(\n",
    "        rrb.Grid(\n",
    "            *[rrb.Spatial2DView(name=str(field), origin=f\"field_{i}\")\n",
    "              for i, field in enumerate(fields)],\n",
    "        ),\n",
    "        rrb.TimeSeriesView(name=\"Losses\", origin=\"/\", defaults=[rr.components.AggregationPolicyBatch(\"average\")]),\n",
    "        row_shares=[0.7,0.3]\n",
    "    ),\n",
    "    collapse_panels=True\n",
    ")\n",
    "for i, field in enumerate(fields):\n",
    "    rr.log(f\"loss/field_{i}\", rr.SeriesLine(name=str(field)), static=True)\n",
    "\n",
    "rr.notebook_show(blueprint=blueprint, width=1050, height=800)\n",
    "\n",
    "@torch.no_grad()\n",
    "def log_field_as_image(entity_path: str, field: NeuralField, min_uv: Tuple[float], max_uv: Tuple[float], uv_resolution: Tuple[int]): \n",
    "    u_values = torch.linspace(min_uv[0], max_uv[0], uv_resolution[0])\n",
    "    v_values = torch.linspace(min_uv[1], max_uv[1], uv_resolution[1])\n",
    "    uv_points = torch.cartesian_prod(u_values, v_values) + 0.5 / torch.tensor(uv_resolution)  # 0.5 is the center of a pixel\n",
    "    predictions = field(uv_points)\n",
    "    image_prediction = torch.clamp(predictions.reshape(uv_resolution[0], uv_resolution[1], 3), 0, 1)\n",
    "    image_prediction = image_prediction.permute(1, 0, 2)\n",
    "    rr.log(entity_path, rr.Image(image_prediction.numpy(force=True)))\n",
    "\n",
    "\n",
    "rr.set_time_sequence(\"iteration\", 0)\n",
    "for i, field in enumerate(fields):\n",
    "    log_field_as_image(f\"field_{i}\", field, (-0.1, -0.1), (1.1,1.1), (100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b8e80-e69d-4b6b-be51-50cbf4c20495",
   "metadata": {},
   "source": [
    "## Train neural field\n",
    "\n",
    "Now we train the neural fields for a fixed number of iterations. If you run the cell twice, we continue training where we left off. To reset the fields, run the previous cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19545879-9f90-489d-9b50-27fa485a5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_ids = [0,1,2, 3]  # if you only want to train one of the fields\n",
    "num_iterations = 10000\n",
    "batch_size = 1000\n",
    "learning_rate = 1e-4\n",
    "\n",
    "for field_id in field_ids:\n",
    "    field = fields[field_id]\n",
    "    for iteration in range(num_iterations):\n",
    "        total_iterations[field_id] += 1\n",
    "        rr.set_time_sequence(\"iteration\", total_iterations[field_id])\n",
    "        rr.log(f\"loss/field_{field_id}\", rr.Scalar(torch.rand(1,).item()))\n",
    "        # train_field(fields[field_id], num_iterations, batch_size, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
